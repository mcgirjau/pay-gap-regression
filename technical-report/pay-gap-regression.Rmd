---
title: "A Regression Analysis of the Gender Pay Gap \\ (Technical Report)"
author: "Maria-Cristiana Gîrjău"
date: "December 2019"
output: 
  pdf_document:
    fig_height: 3
    fig_width: 5
    toc: TRUE
    number_sections: TRUE
fontsize: 11pt
geometry: margin=1in
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
# Loading necessary packages
library(readr)
library(mosaic)
library(dplyr)
library(ggplot2)
library(forcats)
library(purrr)
library(stringr)
library(kableExtra)
library(GGally)
library(leaps)
library(cowplot)
library(tidyr)
library(ggrepel)
library(xtable)

# Tweaks to adjust code chunk font size
chunk_hook <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- chunk_hook(x, options)
  ifelse(options$size != "normalsize", 
         paste0("\n \\", options$size, "\n\n", x, "\n\n \\normalsize"), x)
})

# Setting default chunk and display options
knitr::opts_chunk$set(
  comment = NA, # remove all hashes from the output
  tidy = FALSE, # display code as typed
  comment = "\t", # tab plain R output
  size = "small", # smaller font for code
  fig.align = "center", # center figures
  warning = F, message = F) # suppress warnings & messages in knitted doc

# B&W ggplot2 theme
theme_set(theme_bw())

# Do not immediately use scientific notation
options(scipen = 1)
```

\newpage

# Data Wrangling

## Data Import

Importing both the provided sample and the full original PUMS dataset (merged, pre-wrangled, and filtered appropriately in an .R script). The provided sample will be used for analysis, while the full dataset might come in handy for certain visualizations such as maps, which require more data to be meaningful.

```{r import}
# Sample of 3000 to be wrangled in RMarkdown
ACSSmallRaw <- readr::read_csv("data/ACS3k.csv")

# Full dataset (already wrangled, see .R script for details)
ACSBig <- readRDS("data/ACSBig.Rds")
```

## Preparation

Preparing the levels for the factor variables we intend to recode.

```{r factors}
# Setting factor levels
sex_levels <- c(M = "1",
                "F" = "2")

# will only be used for tallying
race_levels <- c(White = "1",
                 Black = "2",
                 Native = "3",
                 Native = "4",
                 Native = "5",
                 Asian = "6",
                 Native = "7",
                 Other = "8",
                 Multiple = "9")

# will only be used for tallying
marital_status_levels <- c(Married = "1",
                           Widowed = "2",
                           Divorced = "3",
                           Separated = "4",
                           Single = "5")

# collapsing degree
degree_levels <- c("Agriculture" = "11",
                   "Environmental" = "13",
                   "Architecture" = "14",
                   "Ethnic Studies" = "15",
                   "Media and Journalism" = "19",
                   "Communication" = "20",
                   "Computer Science and IT" = "21",
                   "Cosmetology and Gastronomy" = "22",
                   "Education" = "23",
                   "Engineering" = "24",
                   "Engineering" = "25",
                   "Languages" = "26",
                   "Consumer Sciences" = "29",
                   "Law and Policy" = "32",
                   "English Literature" = "33",
                   "Liberal Arts" = "34",
                   "Library Science" = "35",
                   "Biological Sciences" = "36",
                   "Mathematics and Statistics" = "37",
                   "Military" = "38",
                   "Interdisciplinary" = "40",
                   "Fitness" = "41",
                   "Philosophy" = "48",
                   "Theology" = "49",
                   "Physical Sciences" = "50",
                   "Physical Sciences" = "51",
                   "Psychology" = "52",
                   "Law and Policy" = "53",
                   "Law and Policy" = "54",
                   "Social Sciences" = "55",
                   "Construction" = "56",
                   "Construction" = "57",
                   "Transportation" = "59",
                   "Arts" = "60",
                   "Medicine" = "61",
                   "Business and Finance" = "62",
                   "History" = "64")

# will be used for filtering
employment_levels <- c("Employed working" = "1",
                       "Employed not working" = "2",
                       Unemployed = "3",
                       "Military working" = "4",
                       "Military not working" = "5",
                       "Not in labor force" = "6")

region_levels <- c(Northeast = "1",
                   Midwest = "2",
                   South = "3",
                   West = "4",
                   "Puerto Rico" = "9")

state_levels <- c(AL = "1",
                  AK = "2",
                  AZ = "4",
                  AR = "5",
                  CA = "6",
                  CO = "8",
                  CT = "9",
                  DE = "10",
                  DC = "11",
                  FL = "12",
                  GA = "13",
                  HI = "15",
                  ID = "16",
                  IL = "17",
                  IN = "18",
                  IA = "19",
                  KS = "20",
                  KY = "21",
                  LA = "22",
                  ME = "23",
                  MD = "24",
                  MA = "25",
                  MI = "26",
                  MN = "27",
                  MS = "28",
                  MO = "29",
                  MT = "30",
                  NE = "31",
                  NV = "32",
                  NH = "33",
                  NJ = "34",
                  NM = "35",
                  NY = "36",
                  NC = "37",
                  ND = "38",
                  OH = "39",
                  OK = "40",
                  OR = "41",
                  PA = "42",
                  RI = "44",
                  SC = "45",
                  SD = "46",
                  TN = "47",
                  TX = "48",
                  UT = "49",
                  VT = "50",
                  VA = "51",
                  WA = "53",
                  WV = "54",
                  WI = "55",
                  WY = "56",
                  "Puerto Rico" = "72")

# collapsing industry
industry_levels <- c("Agriculture, Forestry, Fishing and Hunting" = "11",
                     "Mining, Quarrying, and Oil and Gas Extraction" = "21",
                     "Utilities" = "22",
                     "Construction" = "23",
                     "Manufacturing" = "31",
                     "Manufacturing" = "32",
                     "Manufacturing" = "33",
                     "Manufacturing" = "3M",
                     "Wholesale Trade" = "42",
                     "Retail Trade" = "44",
                     "Retail Trade" = "45",
                     "Transportation and Warehousing" = "48",
                     "Transportation and Warehousing" = "49",
                     "Information" = "51",
                     "Finance and Insurance" = "52",
                     "Real Estate and Rental and Leasing" = "53",
                     "Professional, Scientific, and Technical Services" = "54",
                     "Management of Companies and Enterprises" = "55",
                     "Administrative and Support and Waste Management 
                     and Remediation Services" = "56",
                     "Educational Services" = "61",
                     "Health Care and Social Assistance" = "62",
                     "Arts, Entertainment, and Recreation" = "71",
                     "Accommodation and Food Services" = "72",
                     "Other Services (except Public Administration)" = "81",
                     "Public Administration" = "92")
```

## Variable Selection

Selecting the variables of interest (see the Data Dictionary in Appendix A for details), renaming and mutating them appropriately, and filtering based on specific criteria.

```{r variables}
# Wrangling the data
ACSSmall <- ACSSmallRaw %>%
  
  # Adjusting income
  mutate(ADJINC.x = ADJINC.x / 10^6, # adding decimal point to ADJINC
         WAGP = WAGP * ADJINC.x, # adjusting dollar amounts for inflation
         WAGP = round(WAGP)) %>% # rounding to nearest dollar
  
  # Selecting which variables to keep
  select(SEX, AGEP, CIT, RAC1P, MIL, DIS, # general demographics
         NP, MAR, NRC, # family and household
         SCHL, FOD1P, FOD2P, SCIENGP, # educational background
         ESR, WKHP, NAICSP, # employment
         WAGP, # income
         REGION.x, ST.x) %>% # location
  
  # Renaming the variables
  rename(sex = SEX,
         age = AGEP,
         citizenship = CIT,
         race = RAC1P,
         military = MIL,
         disabled = DIS,
         people_in_household = NP,
         marital_status = MAR,
         children = NRC,
         education = SCHL,
         degree_1 = FOD1P,
         degree_2 = FOD2P,
         stem_degree = SCIENGP,
         employment = ESR,
         hours_per_week = WKHP,
         industry = NAICSP,
         wage_income = WAGP,
         region = REGION.x,
         state = ST.x) %>%
  
  # Converting entries to the appropriate data types
  mutate(sex = as.factor(sex) %>%
           forcats::fct_recode(!!!sex_levels),
         
         employment = as.factor(employment) %>%
           forcats::fct_recode(!!!employment_levels),
         
         race = as.factor(race) %>%
           forcats::fct_recode(!!!race_levels),
         
         marital_status = as.factor(marital_status) %>%
           forcats::fct_recode(!!!marital_status_levels),
         
         region = as.factor(region) %>%
           forcats::fct_recode(!!!region_levels),
         
         state = as.factor(state) %>%
           forcats::fct_recode(!!!state_levels),
         
         # for citizenship, 5 stands for not a citizen
         citizenship = ifelse(citizenship == 5, "No", "Yes") %>% 
           as.factor(),
         
         privilege = ifelse(race %in% c("White", "Asian"), 
                                 "Yes", "No") %>%
           as.factor(),
         
         # for military, 4 stands for never enlisted
         military = ifelse(military == 4, "No", "Yes"),
         military = ifelse(is.na(military), "No", military) %>%
           as.factor(),
         
         ever_married = ifelse(marital_status == "Single", "No", "Yes") %>% 
           as.factor(),
         
         # for education, 22, 23, and 24 stand for graduate degrees
         grad_degree = ifelse(education %in% c(22, 23, 24), "Yes", "No"),
         grad_degree = ifelse(is.na(grad_degree), "No", grad_degree) %>%
           as.factor(),
         
         # for STEMdegree, 1 stands for a STEM degree
         stem_degree = ifelse(stem_degree == 1, "Yes", "No"),
         stem_degree = ifelse(is.na(stem_degree), "No", stem_degree) %>%
           as.factor(),
         
         disabled = ifelse(disabled == 1, "Yes", "No") %>% 
           as.factor(),
         
         # Filling empty industry fields with NAs
         industry = ifelse(industry == "", NA, industry),
         # Collapsing industry codes into broad NAICS sectors (only taking the first 
         # two digits of the NAICS code, which represent the broader industry sectors)
         industry = substr(industry, start = 1, stop = 2) %>%
           as.factor() %>%
           fct_recode(!!!industry_levels),
         
         # Collapsing education codes into broader fields (only taking the first 
         # two digits of each code, which represent the broader field)
         degree_1 = substr(degree_1, start = 1, stop = 2) %>%
           as.factor() %>%
           fct_recode(!!!degree_levels),
         degree_2 = substr(degree_2, start = 1, stop = 2) %>%
           as.factor() %>%
           fct_recode(!!!degree_levels),
         # Merging the two degree variables, taking care of NAs and repeated values
         degree = ifelse(is.na(degree_1) | is.na(degree_2),
                         as.character(degree_1),
                         ifelse(as.character(degree_1) == as.character(degree_2),
                                as.character(degree_1),
                                paste(degree_1, degree_2, sep = " and ")))) %>%
  
  # Filtering the individuals of interest
  filter(!(is.na(wage_income)) & wage_income > 0, # salary income is positive
         employment %in% c("Employed working",
                           "Employed not working",
                           "Military working"), # employed and/or working
         age >= 18) %>% # only people over 18
  
  # Removing merged variables and those used for filtering or joining
  select(-employment, -education, -degree_1, -degree_2)  %>%
  
  # Dropping unused factor levels
  mutate_if(is.factor, fct_drop)
```

```{r, remove, include=FALSE, echo=FALSE}
# Removing unused variables
grep("levels", ls(), value = TRUE)
rm(degree_levels, employment_levels, industry_levels, marital_status_levels,
   race_levels, region_levels, sex_levels, state_levels,
   ACSSmallRaw)
```

\newpage

# Data Exploration

In this section, we will be exploring distributions and associations graphically and numerically, as a preparation for our model fitting and in order to better understand our data.

Let's take a look at the variables in our dataset.

```{r categorization}
names(ACSSmall) %>% cat(sep = "\n")
setequal(names(ACSBig), names(ACSSmall))
```

Variables to be used for graphical exploration only (because they have too many levels): state, industry, degree, region.

Variables to be used for our regression: wage_income (NUMERIC RESPONSE), sex, age (NUMERIC), citizenship, privilege, military, disabled, ever_married, children (NUMERIC), stem_degree, grad_degree, hours_per_week (NUMERIC), people_in_household (NUMERIC)

## Univariate Data Exploration

In this section we explore univariate distributions of some of the most important demographic variables, especially those that we aim to include in the regression, to see whether we would benefit from any log transformations. The code is trivial and takes up unnecessary space, so it has been deferred to the appendix (see appendix B - Univariate Data Exploration).

### Sex

```{r univariate_sex_1, echo=FALSE}
ACSSmall %>%
  group_by(sex) %>%
  tally() %>%
  kable(booktabs = TRUE, caption = "Distribution of Sex",
        col.names = c("Sex", "Tally")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))

ggplot(ACSSmall, aes(x = sex, fill= sex)) + 
  geom_bar() + 
  labs(x = "Sex", y = "Count") +
  ggtitle("Distribution of Sex") +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Dark2")
```

### Race

```{r univariate_race_1, echo=FALSE}
ACSSmall %>%
  group_by(race) %>%
  tally() %>%
  kable(booktabs = TRUE, caption = "Distribution of Race",
        col.names = c("Race", "Tally")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))

ggplot(ACSSmall, aes(x = race, fill= race)) + 
  geom_bar() + 
  labs(x = "Race", y = "Count") +
  ggtitle("Distribution of Race") +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Dark2")
```

### Income

```{r univariate_income_1, echo=FALSE}
ACSSmall %>%
  favstats(~wage_income, data = .) %>%
  kable(booktabs = TRUE, caption = "Distribution of Wage Income",
        col.names = c("Min", "Q1", "Median", "Q3", "Max", 
                      "Mean", "SD", "N", "Missing")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))

ggplot(ACSSmall, aes(x = wage_income)) + 
  geom_density(fill = "#E6AB02", alpha = 0.6) + 
  labs(x = "Wage Income", y = "Density") +
  ggtitle("Distribution of Wage Income")
```

We notice that the distribution of wage income is strongly skewed right, so it would be wise to consider a $\text{log}_{10}$ transformation.

```{r univariate_log_income_1, echo=FALSE}
ACSSmall <- ACSSmall %>%
  mutate(log_wage_income = log(wage_income))

ACSBig <- ACSBig %>%
  mutate(log_wage_income = log(wage_income))

ACSSmall %>%
  favstats(~log_wage_income, data = .) %>%
  kable(booktabs = TRUE, caption = "Distribution of Log(Wage Income)",
        col.names = c("Min", "Q1", "Median", "Q3", "Max", 
                      "Mean", "SD", "N", "Missing")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))

ggplot(ACSSmall, aes(x = log_wage_income)) + 
  geom_density(fill = "#E6AB02", alpha = 0.6) + 
  labs(x = "Log(Wage Income)", y = "Density") +
  ggtitle("Distribution of Log(Wage Income)")
```

This looks much better, despite a slight left skew. We shall use ``log_wage_income`` as our response variable, partly because of skewness, but also because income is better considered on a multiplicative rather than additive scale. In other words, \$1,000 is worth a lot more to a poor person than a millionaire because \$1,000 is a much greater fraction of the poor person's wealth.

### Age

```{r univariate_age_1, echo=FALSE}
ACSSmall %>%
  favstats(~age, data = .) %>%
  kable(booktabs = TRUE, caption = "Distribution of Age",
        col.names = c("Min", "Q1", "Median", "Q3", "Max", 
                      "Mean", "SD", "N", "Missing")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))

ggplot(ACSSmall, aes(x = age)) + 
  geom_density(fill = "#E7298A", alpha = 0.6) + 
  labs(x = "Age", y = "Density") +
  ggtitle("Distribution of Age")
```

Understandably, the number of individuals in our sample starts to fall dramatically past the age of 60, since that is usually when the sweet release of death is upon us.

### Region 

```{r univariate_region_1, echo=FALSE}
ACSSmall %>%
  group_by(region) %>%
  tally() %>%
  kable(booktabs = TRUE, caption = "Distribution of Region",
        col.names = c("Region", "Tally")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))

ggplot(ACSSmall, aes(x = region, fill= region)) + 
  geom_bar() + 
  labs(x = "Region", y = "Count") +
  ggtitle("Distribution of Region") +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Dark2")
```

### Marital Status

```{r univariate_married_1, echo=FALSE}
ACSSmall %>%
  group_by(marital_status) %>%
  tally() %>%
  kable(booktabs = TRUE, caption = "Distribution of Marital Status",
        col.names = c("Marital Status", "Tally")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))

ggplot(ACSSmall, aes(x = marital_status, fill= marital_status)) + 
  geom_bar() + 
  labs(x = "Marital Status", y = "Count") +
  ggtitle("Distribution of Marital Status") +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Dark2")
```

## Multivariate Data Exploration

In this section we take a multivariate approach to exploring our data.

```{r}
ACSSmall %>%
  group_by(privilege, sex) %>%
  summarize(average_wage = mean(wage_income))
```

```{r}
ACSSmall %>%
  ggplot(aes(x = age, y = log_wage_income, color = sex)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE) + 
  labs(x = "Age", y = "Log(Wage Income)")
```

It seems like men earn on average more than women of the same age, but the rate of change of log_wage_income as age increases is relatively the same for the two genders. We will later do a nested F test to see whether the rates of change are actually different, and whether we need two regression lines at all.

```{r}
ACSSmall %>%
  ggplot(aes(x = hours_per_week, y = log_wage_income, color = sex)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Average Hours Worked per Week", y = "Log(Wage Income)")
```

It seems like the rate of change of log_wage_income as age increases is higher for women than for men. We will later do a nested F test to see whether the rates of change are indeed different, and whether we need two regression lines at all.

```{r, fig.height=6, fig.width=9}
ACSBig %>%
  group_by(industry, sex) %>%
  summarize(average_income = mean(wage_income)) %>%
  spread(sex, average_income) %>%
  rename(male_income = M, female_income = "F") %>%
  mutate(difference = male_income - female_income) %>%
  ggplot(aes(x = female_income, y = male_income, color = industry, size = difference)) + 
    geom_point() +
    geom_abline(slope = 1, intercept = 0, alpha = 0.5) +
    geom_text_repel(aes(label = industry), size = 4, 
                    segment.color = "transparent") +
    expand_limits(x = 0, y = 0) +
    labs(x = "Average Female Income", y = "Average Male Income") +
    ggtitle("Average Income Difference between Men and Women, by Industry") +
    theme(legend.position = "none")
```

\newpage

# Modeling

Having completed our variable exploration, we suspect that there is a significant association between wage income and gender. Now let us proceed by fitting a regression model, in order to find out which variables help us account for the variability in income, and more specifically whether gender is indeed a significant predictor thereof.

## Choosing Predictors

It is time to select predictors for our model. We shall use the best subsets procedure in order to find a model that accounts for the most variability in income, while also keeping matters simple.

```{r regression_variables}
# Creating a dataset to be used for our predictor selection procedure
ACSReg1 <- ACSSmall %>%
  # selecting the potential predictors...
  select(sex, age, citizenship, privilege, military, disabled, ever_married, children, 
         stem_degree, people_in_household, hours_per_week, grad_degree,
         # ... and the response
         log_wage_income)
```

```{r}
# Using best subsets method
output <- leaps::regsubsets(log_wage_income ~ ., nbest = 1, data = ACSReg1)

with(summary(output), data.frame(adjr2, cp, bic, outmat)) %>%
  arrange(desc(adjr2)) %>%
  rename(R2_adj = adjr2,
         Cp = cp,
         BIC = bic) %>%
  mutate(R2_adj = round(R2_adj * 100, 2),
         Cp = round(Cp, 2),
         BIC = round(BIC, 2)) %>%
  t() %>%
  as.data.frame() %>%
  kable(booktabs = TRUE, col.names = c("Model 1", "Model 2", "Model 3", 
                                       "Model 4", "Model 5", "Model 6",
                                       "Model 7", "Model 8")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), font_size = 9)
```

Our adjusted R squared is not bad, at 42.6\%. Mallows' Cp is a bit concerning, at 16.6 lowest. Let's see if any of our quantitative variables might benefit from the usage of a polynomial model.

```{r, fig.height=2, fig.width=8}
p1 <- ggplot(ACSReg1, aes(x = age, y = log_wage_income)) + 
  geom_jitter(size = 0.2, alpha = 0.5) +
  geom_smooth(se = FALSE, color = "red")

p2 <- ggplot(ACSReg1, aes(x = people_in_household, y = log_wage_income)) + 
  geom_jitter(size = 0.2, alpha = 0.5) +
  geom_smooth(se = FALSE, color = "red")

p3 <- ggplot(ACSReg1, aes(x = hours_per_week, y = log_wage_income)) + 
  geom_jitter(size = 0.2, alpha = 0.5) +
  geom_smooth(se = FALSE, color = "red")

cowplot::plot_grid(p1, p2, p3, nrow = 1)
```

The relationship between ``log(income)`` and ``age`` is visibly curved, so we might want to consider a quadratic model.

```{r}
cor(ACSReg1 %>% select(log_wage_income, children, people_in_household, age, 
                       hours_per_week), use = "complete.obs") %>% 
  kable(digits = 3, booktabs = TRUE, caption = "Correlation Matrix for Numeric Variables") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), font_size = 9)
```

The correlation matrix for our quantitative predictors also shows that ``people_in_household`` and ``children`` are highly correlated (0.744), so we might as well remove one of them to avoid multicollinearity in our final model. We remove ``children`` since it is less correlated with our response, ``log_wage_income`` (-0.040), than ``people_in_household`` (-0.144).

```{r}
ACSReg2 <- ACSReg1 %>%
  # Adding in squared age as a predictor
  mutate(ageSq = age^2) %>%
  # Removing highly correlated predictor
  select(-children)
```

Now let's run the best subsets procedure again:

```{r}
output <- leaps::regsubsets(log_wage_income ~ ., nbest = 1, data = ACSReg2)

with(summary(output), data.frame(adjr2, cp, bic, outmat)) %>%
  arrange(desc(adjr2)) %>%
  rename(R2_adj = adjr2,
         Cp = cp,
         BIC = bic) %>%
  mutate(R2_adj = round(R2_adj * 100, 2),
         Cp = round(Cp, 2),
         BIC = round(BIC, 2)) %>%
  t() %>%
  as.data.frame() %>%
  kable(booktabs = TRUE, col.names = c("Model 1", "Model 2", "Model 3", 
                                       "Model 4", "Model 5", "Model 6",
                                       "Model 7", "Model 8")) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"), font_size = 9)
```

The adjusted R squared for the best model has increased from 42.7\% to 49\%, and Mallows' Cp has decreased to 10.6. The BIC has also decreased significantly from -645 to -812. This looks promising! Let's fit the corresponding model now.

```{r}
initialModel <- lm(log_wage_income ~ sex + age + ageSq + citizenship + privilege +
              stem_degree + hours_per_week + grad_degree, data = ACSReg2)
msummary(initialModel)
```

This looks good! All of our predictors are significant individually (see p-values for the t-statistics), as is our model as a whole (see p-value for the F-statistic). Let's now play around now using manual forward selection and see if any interaction terms might be of use. We will add the interaction between ``sex`` and ``hours_per_week`` since it adds the biggest increase in adjusted R squared.

```{r}
model <- lm(log_wage_income ~ sex * hours_per_week + age + ageSq + citizenship + 
              privilege + stem_degree + grad_degree, data = ACSReg2)
msummary(model)
```

This model looks good! We have 7 predictors. We could cut some for the interest of simplicity without too much of an impact on the adjusted R squared, but 7 predictors is not excessive so we shall leave all of them in.

## Fitting Model

We now fit our final model.

```{r}
bestModel <- lm(log_wage_income ~ sex * hours_per_week + age + ageSq + citizenship + 
                  privilege + stem_degree + grad_degree, data = ACSReg2)
msummary(bestModel)
```

## Confidence intervals

```{r}
(100 * (confint(bestModel) %>% exp() - 1))
```

(exp(0.24002195) - 1) * 100
(exp(0.23423660) - 1) * 100
etc.

\newpage

# Analysis

## Interpretation

Let's interpret our model. Each of the coefficients are significant, so we interpret.

Since our response is log-transformed, we will give our interpretation in terms of percentage change.

Sex: coefficient of -0.85632199 so if you're a woman (adjusting for the other predictors) that is associated with a $(e^{-0.85632199} - 1) \cdot 100 = -57.52787\%$ lower wages than for men.

log(income for man) = sth
log(income for woman) = sth - 0.856
log(income for woman) - log(income for man) = -0.856
log(income for woman / income for man) = -0.856
income for woman / income for man = e^(-0.856)
so income for woman = income for man * e^(-0.856) = income for man * 0.4247213

For a man, every additional 5 hours worked per week are associated with $(e^{5 \cdot 0.03369606} - 1) \cdot 100 = 18.35049\%$ higher wages. But for women, every additional 5 hours worked per week are only associated with $(e^{5 \cdot (0.03369606 - 0.01616058)} - 1) \cdot 100 = 28.31054\%$ higher wages! Interesting.

## Nested F-test

Now let's come back to our question of interest - does sex matter in predicting wage?

```{r}
bestModel <- lm(log_wage_income ~ sex * hours_per_week + age + ageSq + citizenship + 
                  privilege + stem_degree + grad_degree, data = ACSReg2)
reducedModel <- lm(log_wage_income ~ age + ageSq + hours_per_week + citizenship + 
                     privilege + stem_degree + grad_degree, data = ACSReg2)
anova(reducedModel, bestModel)

reducedModel <- lm(log_wage_income ~ age + ageSq + sex + hours_per_week + citizenship + 
                     privilege + stem_degree + grad_degree, data = ACSReg2)
anova(reducedModel, bestModel)

fullModel <- lm(log_wage_income ~ sex * hours_per_week + sex * age + age + ageSq +
                  citizenship + privilege + stem_degree + grad_degree, 
                data = ACSReg2)
reducedModel <- lm(log_wage_income ~ sex * hours_per_week + age + ageSq + citizenship + 
                  privilege + stem_degree + grad_degree, data = ACSReg2)
anova(reducedModel, fullModel)
```

\newpage

# Assessment

## Conditions

Diagnostic plots to check conditions:

```{r, fig.height=3, fig.width=10}
diagnostic <- function(model, binwidth) {
  
  # Scatterplot of the residuals
  r1 <- ggplot(data = model, aes(x = .fitted, y = .resid)) +
    geom_point(alpha = 0.5) +
    geom_smooth(color = "red", se = FALSE) +
    geom_hline(yintercept = 0, linetype = 2, color = "grey") +
    xlab("Fitted Values") +
    ylab("Residuals") +
    ggtitle("Scatterplot of the Residuals")
  
  # Normal QQ-plot
  r2 <- ggplot(data = model, aes(sample = .resid)) +
    geom_qq(alpha = 0.5) +
    geom_qq_line() +
    xlab("Theoretical Quantiles") +
    ylab("Sample Quantiles") +
    ggtitle("Normal Q-Q Plot")
  
  # Histogram of the residuals
  r3 <- ggplot(data = model, aes(x = .resid, y = ..count..)) +
    geom_histogram(fill = "navy", binwidth = binwidth) +
    xlab("Residual") + 
    ylab("Count") +
    ggtitle("Histogram of the Residuals")
  
  # Plotting all three side by side
  cowplot::plot_grid(plotlist = list(r1, r2, r3), nrow = 1)
}

diagnostic(bestModel, binwidth = NULL)
```

Nice model - we like !!

## Cross-validation Correlation

```{r}
set.seed(1)

# Creating test dataset
ACSTest <- sample(ACSBig %>% mutate(ageSq = age^2), size = 2000)

# Computing predictions
ACSTestPred <- ACSTest %>%
  mutate(prediction = predict(bestModel, newdata = .)) %>%
  select(log_wage_income, prediction)

# Finding cross validation correlation
cross_val_cor <- cor(ACSTestPred$log_wage_income, ACSTestPred$prediction)
cross_val_cor

# Plotting actual values against predictions
ggplot(ACSTestPred, aes(x = log_wage_income, y = prediction)) + 
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(x = "Actual Value", y = "Predctions") +
  ggtitle("Predictions vs. Actual Values")

r_squared <- 0.5007
shrinkage <- r_squared - cross_val_cor^2
shrinkage
```

The cross validation correlation is not bad - over 70\%. Our model is accurate less than half the time This means that our predictive model is expected to perform decently in practice (i.e. when applied to data that was not used in our estimations).

## Logistic Regression

```{r}
ACSLogit <- ACSSmall %>%
  # selecting the potential predictors...
  select(sex, age, citizenship, privilege, military, disabled, ever_married, children, 
         stem_degree, people_in_household, hours_per_week, grad_degree,
         # ... and the response
         wage_income) %>%
  # Adding in squared age as a predictor
  mutate(ageSq = age^2) %>%
  # Dichotomizing outcome
  mutate(wealthy = ifelse(wage_income >= 120000, 1, 0) %>%
           as.factor()) %>%
  select(-wage_income)

tally(ACSLogit$wealthy ~ ACSLogit$sex)
```

```{r}
model1 <- glm(wealthy ~ ., data = ACSLogit, family = binomial(logit), 
              na.action = na.exclude)
msummary(model1)
```

Let's remove what seems most insignificant - citizenship and ever_married. People in household and children are highly correlated so we'll remove one.

```{r}
ACSLogit2 <- ACSLogit %>%
  select(-ever_married, - citizenship)

model2 <- glm(wealthy ~ ., data = ACSLogit2, family = binomial(logit), 
              na.action = na.exclude)
msummary(model2)

model2a <- glm(wealthy ~ .-children, data = ACSLogit2, family = binomial(logit), 
              na.action = na.exclude)

model2b <- glm(wealthy ~ .-people_in_household, data = ACSLogit2, family = binomial(logit), 
              na.action = na.exclude)
msummary(model2a)
msummary(model2b)
```

We remove people in household, as well as disabled and military.

```{r}
ACSLogit3 <- ACSLogit2 %>%
  select(-people_in_household, -disabled, -military)

model3 <- glm(wealthy ~ ., data = ACSLogit3, family = binomial(logit), 
              na.action = na.exclude)
msummary(model3)
```

Try to remove some more?

```{r}
ACSLogit4 <- ACSLogit3 %>%
  select(-privilege, -children)

model4 <- glm(wealthy ~ ., data = ACSLogit4, family = binomial(logit), 
              na.action = na.exclude)
msummary(model4)
```

No no, AIC grows. model3 looked good. Interactions? Trying some, no.

```{r}
model5 <- glm(wealthy ~ . + hours_per_week * stem_degree, data = ACSLogit3, family = binomial(logit), 
              na.action = na.exclude)
msummary(model5)
```

```{r}
# Amy Wagaman's function to calculate coconcordance
getConcordance <- function(model){
  Con_Dis_Data <- cbind(model$y, model$fitted.values)
  ones <- Con_Dis_Data[Con_Dis_Data[,1] == 1,]
  zeros <- Con_Dis_Data[Con_Dis_Data[,1] == 0,]
  conc <- matrix(0, dim(zeros)[1], dim(ones)[1])
  disc <- matrix(0, dim(zeros)[1], dim(ones)[1])
  ties <- matrix(0, dim(zeros)[1], dim(ones)[1])
  for(j in 1:dim(zeros)[1]){
    for(i in 1:dim(ones)[1]){
      if(ones[i,2]>zeros[j,2]){
        conc[j,i]=1
      }else if(ones[i,2]<zeros[j,2]){
          disc[j,i]=1
      }else if(ones[i,2]==zeros[j,2]){
        ties[j,i]=1
      }
    }
  }
  Pairs <- dim(zeros)[1]*dim(ones)[1]
  PercentConcordance <- (sum(conc)/Pairs)*100
  PercentDiscordance <- (sum(disc)/Pairs)*100
  PercentTied <- (sum(ties)/Pairs)*100
  return(list("Percent Concordance" = PercentConcordance,
              "Percent Discordance" = PercentDiscordance,
              "Percent Tied" = PercentTied,
              "Pairs" = Pairs))
}
```

```{r}
getConcordance(model3)
```

```{r}
ACSLogit3 <- mutate(ACSLogit3, predProb = predict(model, type = "response"),
                    predComplete = ifelse(predProb > 0.9, 1, 0))
# cross-tally predicted successes with actual success
tally(data = ACSLogit3, wealthy ~ predComplete, margins = TRUE)
```

ADD EMPIRICAL LOGIT PLOTS

Testing

```{r}
library(lmtest)
lrtest(model3)
```

```{r}
model3_nosex <- glm(wealthy ~ age + privilege + children + stem_degree + 
                      hours_per_week + grad_degree + ageSq, 
                    data = ACSLogit3, family = binomial(logit), 
                    na.action = na.exclude)
lrtest(model3_nosex, model3)
```

\newpage

# Appendices

<!--
Visualizations:
- cluster based on income and other stuff, and observe different proportions of men and women in the clusters
- heatmap of wage difference by industry and by degree
- interactive balloon chart for every industry or degree
- interactive map of wage differences by state and by region

- Z test to see if proportion of household income contributed by men's wages is significantly different than proportion of household income contributed by women's wages -->

## Appendix A - Data Dictionary

A number of variables have been identified as potentially relevant to the issue of the gender pay gap. Optimally, a careful consideration of each of them might provide us with a more precise understanding of the relationship between gender and income. However, only some of the variables below will make it into our final regression models - some will be used for filtering (e.g. \textbf{employment}), others are intended for creating meaningful visualizations (e.g. \textbf{state}, \textbf{industry}), and others might prove to have an insignificant effect on the relationship between gender and income.

In the list below, variables have been grouped under general topics, and we have included their names as they appear in the original data set, their new names as assigned for our analysis, as well as their respective descriptions from the Data Dictionary. For each individual, we will look at:

\begin{enumerate}
    \item General demographics:
    \begin{enumerate}
        \item \textbf{SEX} (renamed to \textbf{sex}) - \textit{``Sex''} \\ 
        (FACTOR WITH TWO LEVELS)
        \item \textbf{AGEP} (renamed to \textbf{age}) - \textit{``Age''}
        \item \textbf{CIT} (renamed to \textbf{citizenship}) - \textit{``Citizenship Status''}
        \item \textbf{RAC1P} (renamed to \textbf{race}) - \textit{``Recoded detailed race code''}
        \item \textbf{MIL} (renamed to \textbf{military}) - \textit{``Military service''}
        \item \textbf{DIS} (renamed to \textbf{disabled}) - \textit{``Disability recode''}
    \end{enumerate}
    \item Family and household:
    \begin{enumerate}
        \item \textbf{MAR} (renamed to \textbf{married})- \textit{``Marital status''}
        \item \textbf{NRC} (renamed to \textbf{children\_no}) - \textit{``Number of related children in household (unweighted)''}
    \end{enumerate}
        \item Educational background:
    \begin{enumerate}
        \item \textbf{SCHL} (renamed to \textbf{education}) - \textit{``Educational attainment''}
        \item \textbf{FOD1P} (will be merged with \textbf{FOD2P} to create \textbf{degree}) - \textit{``Recoded field of degree - first entry''}
        \item \textbf{FOD2P} (will be merged with \textbf{FOD1P} to create \textbf{degree}) - \textit{``Recoded field of degree - second entry''} \footnote{e.g. for double majors or dual degrees}
        \item \textbf{SCIENGP} - (renamed to \textbf{stem\_degree}) \textit{``Field of Degree Science and Engineering Flag - NSF Definition''}
    \end{enumerate}
    \item Employment:
    \begin{enumerate}
        \item \textbf{ESR} (renamed to \textbf{employment}) - \textit{``Employment status recode''}
        \item \textbf{WKHP} (renamed to \textbf{hours\_per\_week}) - \textit{``Usual hours worked per week past 12 months'}
        \item \textbf{NAICSP} (renamed to \textbf{industry}) - \textit{``NAICS Industry recode for 2013 and later based on 2012 NAICS codes''}
    \end{enumerate}
    \item Income:
    \begin{enumerate}
        \item \textbf{WAGP} (renamed to \textbf{wage\_income}) - \textit{``Wages or salary income past 12 months (use ADJINC to adjust WAGP to constant dollars)''}
        \item \textbf{ADJINC} (not renamed, will be used during data wrangling to adjust dollar amounts, then discarded) - \textit{``Adjustment factor for income and earnings dollar amounts''}
    \end{enumerate}
    \item Location:
    \begin{enumerate}
        \item \textbf{REGION} (renamed to \textbf{region}) - \textit{``Region code based on 2010 Census definitions''}
        \item \textbf{ST} (renamed to \textbf{state}) - \textit{``State Code based on 2010 Census definitions''}
    \end{enumerate}
\end{enumerate}

```{r eval=FALSE, echo=FALSE, include=FALSE}
# How many clusters would we need? Let's make an elbow plot...
tot_withinss <- map_dbl(1:10,  function(k) {
  model <- kmeans(ACSBig %>% select(wage_income, age, children_no) %>% na.omit(), centers = k)
  model$tot.withinss
})

elbow_df <- data.frame(
  k = 1:10,
  tot_withinss = tot_withinss
)

ggplot(elbow_df, aes(x = k, y = tot_withinss)) +
  geom_line() +
  scale_x_continuous(breaks = 1:10)

clusters <- ACSBig %>%
  select(wage_income, age, children_no) %>%
  na.omit() %>%
  kmeans(centers = 3) %>%
  fitted("classes") %>%
  as.factor()

ACSBigClustered <- ACSBig %>%
  select(wage_income, age, children_no, sex) %>%
  na.omit() %>%
  mutate(cluster = clusters)

ggpairs(ACSBigClustered %>% select(wage_income, sex, cluster), mapping = aes(color = cluster))

ggplot(ACSBigClustered, aes(x = sex, fill = cluster)) +
  geom_bar()

prop.table(table(ACSBigClustered$sex, ACSBigClustered$cluster), margin = 2) * 100
```

## Appendix B - Code for Univariate Data Exploration

The code from the Univariate Data Exploration section appears here.

### Sex

```{r univariate_sex_2, ref.label='univariate_sex_1', echo=TRUE, results='markup', eval=FALSE}

```

### Race

```{r univariate_race_2, ref.label='univariate_race_1', echo=TRUE, results='markup', eval=FALSE}

```

### Income

```{r univariate_income_2, ref.label='univariate_income_1', echo=TRUE, results='markup', eval=FALSE}

```

```{r univariate_log_income_2, ref.label='univariate_log_income_1', echo=TRUE, results='markup', eval=FALSE}

```

### Age

```{r univariate_age_2, ref.label='univariate_age_1', echo=TRUE, results='markup', eval=FALSE}

```

### Region 

```{r univariate_region_2, ref.label='univariate_region_1', echo=TRUE, results='markup', eval=FALSE}

```

### Marital Status

```{r univariate_married_2, ref.label='univariate_married_1', echo=TRUE, results='markup', eval=FALSE}

```
