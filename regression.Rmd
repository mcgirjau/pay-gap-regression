---
title: "Regression"
author: "Maria-Cristiana Gîrjău"
date: "10/27/2019"
output: pdf_document
---

```{r}
# Load necessary packages
require(mosaic)
require(ggplot2)
require(dplyr)
require(kableExtra) 
require(stargazer)
require(Stat2Data)
require(visreg)
require(car)
```

- divide up variables into those for exploration and those for regression
- cluster
- heatmap of wage difference
- interactive balloon chart
- interactive map of wage differences
- best subsets selection
- analysis of the model
- F-test and z-test
- LOG transformation

```{r}
ACSSample <- readRDS("data/ACSSample.Rds")
```

```{r}
names(ACSSample)
ACSReg <- ACSSample %>% select(sex, age, wage_income, children_no, race)
```

```{r}
# we use a method described in the book for finding
# the model with the highest adjusted R squared, and lowest Cp

# # we create a new data frame to include interaction terms
# ACSReg <- ACSReg %>%
#   # creating the interaction terms
#   mutate(sexage = sex * age,
#          sexno = sex * children_no,
#          ageno = age * children_no)

library(leaps)
output <- summary(regsubsets(wage_income ~ ., nbest = 2, data = ACSReg))
subsets <- output$which
R2 <- round(100 * output$rsq, 1)
R2adj <- round(100 * output$adjr2, 1)
Cp <- round(output$cp, 1)
cbind(as.data.frame(subsets), R2, R2adj, Cp) %>%
  # we want the highest adjusted R squared
  arrange(desc(R2adj)) %>%
  kable(booktabs = TRUE) %>%
  kable_styling(latex_options = "striped", font_size = 6)

# we pick the best model from the output
bestModel <- lm(log(wage_income) ~ ., data = ACSReg)
msummary(bestModel)
```
